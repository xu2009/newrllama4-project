#!/usr/bin/env Rscript

# ç®€åŒ–çš„EOGæµ‹è¯•ï¼šä¸“æ³¨äºæ ¸å¿ƒé—®é¢˜
library(newrllama4)

cat("=== ç®€åŒ–EOGé—®é¢˜è¯Šæ–­ ===\n\n")

if (!lib_is_installed()) {
  install_newrllama()
}

# æµ‹è¯•ä¸€ä¸ªæ˜ç¡®ä¼šäº§ç”Ÿ<|eot_id|>çš„åœºæ™¯
model_path <- "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf"

cat("ğŸ“¥ åŠ è½½æ¨¡å‹...\n")
model <- model_load(model_path, n_gpu_layers = 100L, verbosity = 0L)
ctx <- context_create(model, n_ctx = 512L, verbosity = 0L)

# æµ‹è¯•å…³é”®é—®é¢˜ï¼šä¸ºä»€ä¹ˆllama_vocab_is_eog()æ²¡æœ‰å·¥ä½œï¼Ÿ
cat("\nğŸ” æ ¸å¿ƒé—®é¢˜ï¼šllama_vocab_is_eog()æ£€æµ‹\n")
cat(strrep("=", 50), "\n")

# ä½¿ç”¨ç®€å•çš„ç”Ÿæˆæµ‹è¯•
test_prompt <- "Hello"
tokens_in <- tokenize(model, test_prompt)
cat(sprintf("æµ‹è¯•prompt: '%s'\n", test_prompt))
cat(sprintf("TokenåŒ–ç»“æœ: [%s]\n", paste(tokens_in, collapse = ", ")))

# ç”Ÿæˆå¹¶è§‚å¯Ÿæ˜¯å¦åŒ…å«EOG tokens  
cat("\nğŸ“¤ è°ƒç”¨åº•å±‚generate (max_tokens=50):\n")
result <- generate(model, ctx, tokens_in, max_tokens = 50L)
cat(sprintf("ç”Ÿæˆç»“æœ: '%s'\n", result))
cat(sprintf("ç»“æœé•¿åº¦: %d å­—ç¬¦\n", nchar(result)))

# å…³é”®åˆ†æï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«EOG tokens
eog_patterns <- c("<\\|eot_id\\|>", "<\\|end_header_id\\|>", "<\\|start_header_id\\|>")
found_eogs <- c()

for (pattern in eog_patterns) {
  if (grepl(pattern, result)) {
    matches <- gregexpr(pattern, result)[[1]]
    found_eogs <- c(found_eogs, sprintf("%s at position %s", 
                                        pattern, 
                                        paste(matches, collapse = ",")))
  }
}

if (length(found_eogs) > 0) {
  cat("\nâŒ å‘ç°EOG tokensåœ¨è¾“å‡ºä¸­:\n")
  for (eog in found_eogs) {
    cat(sprintf("  - %s\n", eog))
  }
  cat("\nğŸ”§ è¿™æ„å‘³ç€llama_vocab_is_eog()æ²¡æœ‰æ­£ç¡®è¯†åˆ«è¿™äº›tokens\n")
  
  # å¯èƒ½çš„åŸå› åˆ†æ
  cat("\nğŸ“‹ å¯èƒ½åŸå› :\n")
  cat("  1. æ¨¡å‹çš„special_eog_idsé›†åˆä¸åŒ…å«è¿™äº›multi-tokenåºåˆ—\n")
  cat("  2. llama_vocab_is_eog()åªæ£€æŸ¥å•ä¸ªtokenï¼Œä¸æ£€æŸ¥å®Œæ•´çš„åºåˆ—\n")
  cat("  3. è¿™äº›ä¸æ˜¯çœŸæ­£çš„single EOG tokensï¼Œè€Œæ˜¯tokenåºåˆ—\n")
  
} else {
  cat("\nâœ… æ²¡æœ‰å‘ç°EOG tokens - llama_vocab_is_eog()å¯èƒ½æ­£å¸¸å·¥ä½œ\n")
}

# æµ‹è¯•æ˜¯å¦EOGæ£€æµ‹åœ¨æŸç§æ¡ä»¶ä¸‹å·¥ä½œ
cat("\nğŸ§ª æµ‹è¯•EOS tokenè¡Œä¸º:\n")
simple_result <- generate(model, ctx, tokens_in, max_tokens = 200L)
if (nchar(simple_result) < 200*5) { # ä¼°ç®—å¹³å‡tokené•¿åº¦
  cat("âœ… ç”Ÿæˆæå‰åœæ­¢ï¼Œå¯èƒ½EOGæ£€æµ‹åœ¨æŸäº›æƒ…å†µä¸‹å·¥ä½œ\n")
} else {
  cat("âŒ ç”Ÿæˆæ²¡æœ‰æå‰åœæ­¢ï¼ŒEOGæ£€æµ‹å¯èƒ½å®Œå…¨å¤±æ•ˆ\n")
}

rm(model, ctx)
backend_free()
cat("\nâœ… æµ‹è¯•å®Œæˆ\n")