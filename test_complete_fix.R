# æµ‹è¯•å®Œæ•´çš„åœæ­¢æ ‡è®°ä¿®å¤ï¼ˆå•åºåˆ— + å¹¶è¡Œï¼‰
library(newrllama4)

cat("=== æµ‹è¯•å®Œæ•´åœæ­¢æ ‡è®°ä¿®å¤ ===\n\n")

backend_init()
model_path <- "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/gemma-3-12b-it-q4_0.gguf"
model <- model_load(model_path, verbosity = 0)
ctx <- context_create(model, n_ctx = 512, verbosity = 0)

# æµ‹è¯•1: åŸå§‹é—®é¢˜ - å•åºåˆ—ç”Ÿæˆ
cat("--- æµ‹è¯•1: å•åºåˆ—ç”Ÿæˆä¿®å¤ ---\n")
messages1 <- list(
  list(role = "system", content = "You are a helpful assistant."),
  list(role = "user", content = "What is the square root of 144? Reply with only the number.")
)
formatted_prompt1 <- apply_chat_template(model, messages1)
tokens1 <- tokenize(model, formatted_prompt1)
result1 <- generate(ctx, tokens1, max_tokens = 10)

cat("åŸå§‹é—®é¢˜ç»“æœ: '", result1, "'\n", sep="")
cat("æœŸæœ›: '12'\n")
cat("åŒ…å«åœæ­¢æ ‡è®°: ", grepl("<end_of_turn>|<|im_end|>", result1), "\n")
cat("ä¿®å¤æˆåŠŸ: ", !grepl("<end_of_turn>", result1) && trimws(result1) != "", "\n\n")

# æµ‹è¯•2: å¹¶è¡Œç”Ÿæˆä¿®å¤
cat("--- æµ‹è¯•2: å¹¶è¡Œç”Ÿæˆä¿®å¤ ---\n") 
test_prompts <- c(
  "What is 5+3? Just the number.",
  "Name the color of grass. One word.",
  "What is 10-7? Just the number."
)

formatted_prompts <- sapply(test_prompts, function(prompt) {
  messages <- list(list(role = "user", content = prompt))
  apply_chat_template(model, messages)
})

results2 <- generate_parallel(ctx, formatted_prompts, max_tokens = 5, seed = 123)

cat("å¹¶è¡Œç”Ÿæˆç»“æœ:\n")
all_clean <- TRUE
for(i in 1:length(results2)) {
  clean_result <- trimws(results2[i])
  has_stop_token <- grepl("<end_of_turn>|<|im_end|>", clean_result)
  cat("ç»“æœ", i, ": '", clean_result, "' | æœ‰åœæ­¢æ ‡è®°: ", has_stop_token, "\n", sep="")
  if(has_stop_token) all_clean <- FALSE
}
cat("å¹¶è¡Œç”Ÿæˆå…¨éƒ¨ä¿®å¤: ", all_clean, "\n\n")

# æµ‹è¯•3: è¾¹ç•Œæƒ…å†µ
cat("--- æµ‹è¯•3: è¾¹ç•Œæƒ…å†µæµ‹è¯• ---\n")
edge_prompts <- c(
  "Say 'hello' and stop.",
  "Count: 1, 2, 3",
  "Answer: yes or no?"
)

edge_formatted <- sapply(edge_prompts, function(prompt) {
  messages <- list(list(role = "user", content = prompt))
  apply_chat_template(model, messages)
})

edge_results <- generate_parallel(ctx, edge_formatted, max_tokens = 8, seed = 456)

cat("è¾¹ç•Œæƒ…å†µç»“æœ:\n")
edge_clean <- TRUE
for(i in 1:length(edge_results)) {
  result <- trimws(edge_results[i])
  has_stop <- grepl("<end_of_turn>|<|im_end|>", result)
  cat("è¾¹ç•Œ", i, ": '", result, "' | åœæ­¢æ ‡è®°: ", has_stop, "\n", sep="")
  if(has_stop) edge_clean <- FALSE
}

# æœ€ç»ˆæ€»ç»“
cat("\n=== ä¿®å¤æ•ˆæœæ€»ç»“ ===\n")
cat("âœ… å•åºåˆ—ç”Ÿæˆä¿®å¤: ", !grepl("<end_of_turn>", result1), "\n")
cat("âœ… å¹¶è¡Œç”Ÿæˆä¿®å¤: ", all_clean, "\n") 
cat("âœ… è¾¹ç•Œæƒ…å†µä¿®å¤: ", edge_clean, "\n")

overall_success <- !grepl("<end_of_turn>", result1) && all_clean && edge_clean
cat("ğŸ‰ æ•´ä½“ä¿®å¤æˆåŠŸ: ", overall_success, "\n")

backend_free()
cat("\n=== å®Œæ•´ä¿®å¤æµ‹è¯•å®Œæˆ ===\n")