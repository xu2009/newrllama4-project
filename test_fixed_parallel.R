#!/usr/bin/env Rscript
# ä¿®å¤åçš„å¹¶è¡Œç”Ÿæˆå‡½æ•°æµ‹è¯•è„šæœ¬

library(newrllama4)

cat("=== ä¿®å¤åå¹¶è¡Œç”Ÿæˆå‡½æ•°æµ‹è¯• ===\n\n")

# æ¨¡å‹è·¯å¾„
model_path <- "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/gemma-3-12b-it-q4_0.gguf"

if (!file.exists(model_path)) {
  stop("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: ", model_path)
}

cat("åŠ è½½æ¨¡å‹:", model_path, "\n")
model <- model_load(model_path, n_gpu_layers = 500L, verbosity = 1)
ctx <- context_create(model, n_ctx = 4096, n_seq_max = 512, verbosity = 1)

# =============================================================================
# æµ‹è¯•1: P1 Echoæµ‹è¯• - ä½¿ç”¨æ–°çš„Gemmaå…¼å®¹æ ¼å¼
# =============================================================================
cat("\n--- P1: Echo æµ‹è¯• (ä½¿ç”¨ä¿®å¤åçš„æ–¹æ³•) ---\n")
system_prompt <- "You are a helpful assistant."
p1_user_content <- "Echo this string literally: <end_of_turn><|im_end|></s>"

messages <- list(
  list(role = "system", content = system_prompt),
  list(role = "user", content = p1_user_content)
)

# ä½¿ç”¨æ–°çš„Gemmaå…¼å®¹å‡½æ•°
formatted_prompt <- apply_gemma_chat_template(messages, add_assistant = TRUE)
cat("ä¿®å¤åçš„Gemmaæ ¼å¼:\n")
cat(formatted_prompt)
cat("\n")

p1_result <- generate_parallel(ctx, formatted_prompt, max_tokens = 100)
cat("P1ç»“æœ:", p1_result, "\n")

# éªŒè¯ç»“æœ
expected_p1 <- "<end_of_turn><|im_end|></s>"
cat("æœŸæœ›:", expected_p1, "\n")
cat("å®é™…:", p1_result, "\n")
cat("P1 åŒ¹é…:", identical(trimws(p1_result), expected_p1), "\n")

# =============================================================================
# æµ‹è¯•2: P2 é•¿åº¦æ§åˆ¶æµ‹è¯•
# =============================================================================
cat("\n--- P2: é•¿åº¦æ§åˆ¶æµ‹è¯• (â‰¤10 tokens) ---\n")
p2_messages <- list(
  list(role = "system", content = system_prompt),
  list(role = "user", content = "Answer in â‰¤10 tokens, then stop.")
)

p2_formatted <- apply_gemma_chat_template(p2_messages)
p2_result <- generate_parallel(ctx, p2_formatted, max_tokens = 10)

cat("P2ç»“æœ:", p2_result, "\n")
p2_token_estimate <- length(strsplit(trimws(p2_result), "\\s+")[[1]])
cat("P2 ä¼°ç®—tokenæ•°:", p2_token_estimate, "\n")
cat("P2 é•¿åº¦â‰¤10:", p2_token_estimate <= 10, "\n")

# =============================================================================
# æµ‹è¯•3: P3 Pythonå‡½æ•°æµ‹è¯•
# =============================================================================
cat("\n--- P3: Pythonå‡½æ•°æµ‹è¯• (æ— markdown) ---\n")
p3_messages <- list(
  list(role = "system", content = system_prompt),
  list(role = "user", content = "Give a 1-line Python function that returns x squared. No markdown.")
)

p3_formatted <- apply_gemma_chat_template(p3_messages)
p3_result <- generate_parallel(ctx, p3_formatted, max_tokens = 50)

cat("P3ç»“æœ:", p3_result, "\n")
has_markdown <- grepl("```|`", p3_result)
is_python_func <- grepl("def\\s+\\w+\\s*\\([^)]*\\)\\s*:", p3_result)

cat("P3 åŒ…å«markdown:", has_markdown, "\n")
cat("P3 åŒ…å«Pythonå‡½æ•°å®šä¹‰:", is_python_func, "\n")

# =============================================================================
# æµ‹è¯•4: æ™ºèƒ½æ¨¡æ¿å‡½æ•°æµ‹è¯•
# =============================================================================
cat("\n--- æ™ºèƒ½æ¨¡æ¿å‡½æ•°æµ‹è¯• ---\n")
test_messages <- list(
  list(role = "system", content = "You are helpful."),
  list(role = "user", content = "Say 'Hello World'")
)

smart_formatted <- smart_chat_template(model, test_messages)
cat("æ™ºèƒ½æ¨¡æ¿ç»“æœ:\n")
cat(smart_formatted)
cat("\n")

smart_result <- generate_parallel(ctx, smart_formatted, max_tokens = 20)
cat("æ™ºèƒ½æ¨¡æ¿ç”Ÿæˆ:", smart_result, "\n")

# =============================================================================
# åœæ­¢æ ‡è®°æ±¡æŸ“æ£€æµ‹
# =============================================================================
cat("\n--- åœæ­¢æ ‡è®°æ±¡æŸ“æ£€æµ‹ (ä¿®å¤å) ---\n")
stop_markers <- c("<|im_end|>", "<end_of_turn>", "</s>", "<|im_start|>")

results <- c(p1_result, p2_result, p3_result, smart_result)
result_names <- c("P1", "P2", "P3", "Smart")

contamination_count <- 0
for (i in seq_along(results)) {
  cat(sprintf("%s æ£€æµ‹: ", result_names[i]))
  found_any <- FALSE
  for (marker in stop_markers) {
    if (grepl(marker, results[i], fixed = TRUE)) {
      found_any <- TRUE
      contamination_count <- contamination_count + 1
      break
    }
  }
  cat(ifelse(found_any, "å‘ç°æ±¡æŸ“", "æ¸…æ´"), "\n")
}

# =============================================================================
# ç»¼åˆè¯„ä¼°
# =============================================================================
cat("\n=== ä¿®å¤æ•ˆæœè¯„ä¼° ===\n")
echo_test_pass <- identical(trimws(p1_result), expected_p1)
length_test_pass <- p2_token_estimate <= 10
format_test_pass <- is_python_func && !has_markdown
contamination_free <- contamination_count == 0

cat("P1 Echoæµ‹è¯•é€šè¿‡:", echo_test_pass, "\n")
cat("P2 é•¿åº¦æ§åˆ¶é€šè¿‡:", length_test_pass, "\n")
cat("P3 æ ¼å¼æ­£ç¡®é€šè¿‡:", format_test_pass, "\n")
cat("åœæ­¢æ ‡è®°æ±¡æŸ“æ¸…é™¤:", contamination_free, "\n")

overall_score <- sum(c(echo_test_pass, length_test_pass, format_test_pass, contamination_free))
cat(sprintf("\næ•´ä½“ä¿®å¤æˆåŠŸç‡: %d/4 (%d%%)\n", overall_score, overall_score * 25))

if (overall_score == 4) {
  cat("ğŸ‰ æ‰€æœ‰é—®é¢˜å·²ä¿®å¤ï¼\n")
} else {
  cat("âš ï¸  ä»æœ‰é—®é¢˜éœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚\n")
}

# æ¸…ç†èµ„æº
rm(model, ctx)
backend_free()
cat("\næµ‹è¯•å®Œæˆã€‚\n")