library(readstata13)
library(cregg)
# load function that does clustered SEs
vcovCluster <- function(
model,
cluster
)
{
require(sandwich)
require(lmtest)
if(nrow(model.matrix(model))!=length(cluster)){
stop("check your data: cluster variable has different N than model")
}
M <- length(unique(cluster))
N <- length(cluster)
K <- model$rank
if(M<50){
warning("Fewer than 50 clusters, variances may be unreliable (could try block bootstrap instead).")
}
dfc <- (M/(M - 1)) * ((N - 1)/(N - K))
uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
return(rcse.cov)
}
# read data
d <- read.dta13("conjoint_ps6.dta")
View(d)
lm <- lm(outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven, data=d)
lm_c <- round(coeftest(lm, vcov = vcovCluster(lm, cluster = d$idnum)),4)
lm_c
# unique levels of the attributes
levels(d$atgen)
# unique values of attributes
unique(d$atgen)
# unique values of attributes, such as 0 anf 1
unique(d$atgen)
table(d$atmita)
unique(d$atmita)
levels(d$atmita)
contrasts(d$atmita)
lm_interact <- lm(outcome ~ rural + atgen + atexp + atinti + atmita + atinte + atpol + atven + rural:atgen + rural:atexp + rural:atinti + rural:atmita + rural:atinte + rural:atpol + rural:atven, data=d)
lm_interact_c <- round(coeftest(lm_interact, vcov = vcovCluster(lm_interact, cluster = d$idnum)),4)
lm_interact_c
library(dplyr)
d <- d %>%
mutate(across(c(atgen, atexp, atinti, atmita, atinte, atpol, atven), as.factor))
q3 <- cj(d, outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven, id = ~idnum)
head(q3[c("feature", "level", "estimate", "std.error")], 20L)
plot(q3)
d$rural <- as.factor(d$rural)
d_rural <- d[d$rural == 1, ]
d_urban <- d[d$rural == 0, ]
amce_rural <- cj(d_rural, outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven, id = ~idnum)
amce_urban <- cj(d_urban, outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven, id = ~idnum)
plot(amce_rural, main = "AMCE for Rural Voters")
plot(amce_urban, main = "AMCE for Urban Voters")
d$rural_num <- as.numeric(as.character(d$rural))
d3 = lm(rural_num ~ as.factor(atgen) + as.factor(atexp) + as.factor(atinti) + as.factor(atmita) + as.factor(atinte) + as.factor(atpol) + as.factor(atven), data=d)
d3_cluster = round(coeftest(d3, vcov = vcovCluster(d3, cluster = d$idnum)),2)
d3_cluster
d$fpair = as.factor(d$pair)
d1 = lm(outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven +
fpair +
atgen*fpair + atexp*fpair + atinti*fpair + atmita*fpair + atinte*fpair + atpol*fpair + atven*fpair, data=d)
d1_cluster = round(coeftest(d1, vcov = vcovCluster(d1, cluster = d$idnum)),2)
d1_cluster
d$fcandidate = as.factor(d$candidate)
d2 = lm(outcome ~ atgen + atexp + atinti + atmita + atinte + atpol + atven +
fcandidate +
atgen*candidate + atexp*candidate + atinti*candidate + atmita*candidate + atinte*candidate + atpol*candidate + atven*candidate, data=d)
d2_cluster = round(coeftest(d2, vcov = vcovCluster(d2, cluster = d$idnum)),2)
d2_cluster
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
setwd("/Users/yaoshengleo/Library/CloudStorage/Dropbox/Purdue University/2025 Spring/POL 605 Causal Inference/PS6")
library(optmatch)
library(foreign)
library(designmatch)
library(stargazer)
library(Hmisc)
library(gridExtra)
library(exactRankTests)
library(ggplot2)
library(reshape2)
library(xtable)
library(sensitivitymw)
library(sensitivitymv)
library(readstata13)
#read data
d <- read.dta13("matching_ps6.dta")
# list all the name of the variables
names(d)
# naive regression
naive_model1 <- lm(outcome_crime_stronghand_wave4 ~ t_ind, data = d)
summary(naive_model1)
# naive regression with covariates
naive_model2 <- lm(outcome_crime_stronghand_wave4 ~ t_ind + education + support_deathpenalty + job_formal_sector + support_democracy + militaryfeelingthermometer + age + white + ideology + support_repression + catholic, data = d)
summary(naive_model2)
View(d)
library(MatchIt)
m.out0 <- matchit(t_ind ~ education + support_deathpenalty + job_formal_sector + support_democracy + militaryfeelingthermometer + age + white + ideology + support_repression + catholic,
data = d,
method = NULL,
distance = "glm")
summary(m.out0)
m.out1 <- matchit(t_ind ~ education + support_deathpenalty + job_formal_sector + support_democracy + militaryfeelingthermometer + age + white + ideology + support_repression + catholic,
data = d,
method = "nearest",
distance = "glm")
summary(m.out1, un=FALSE)
plot(m.out1, type="jitter", interactive= FALSE)
plot(summary(m.out1))
m.out2 <- matchit(t_ind ~ education + support_deathpenalty + job_formal_sector + support_democracy + militaryfeelingthermometer + age + white + ideology + support_repression + catholic,
data = d,
method = "cem",
estimand = "ATT")
summary(m.out2, un=FALSE)
plot(summary(m.out2))
m.out3 <- matchit(t_ind ~ education + support_deathpenalty + job_formal_sector + support_democracy + militaryfeelingthermometer + age + white + ideology + support_repression + catholic,
data = d,
method = "cardinality",
estimand = "ATT",
ratio = 1,
solver = "highs")
summary(m.out3, un=FALSE)
plot(summary(m.out3))
m.data <- match.data(m.out3)
head(m.data)
summary(lm(outcome_crime_stronghand_wave4 ~ t_ind, data = m.data))
m.data2 <- match.data(m.out2)
head(m.data2)
# calculate the difference-in-means by hand
mean_treated <- mean(m.data2$outcome_crime_stronghand_wave4[m.data2$t_ind == 1])
mean_control <- mean(m.data2$outcome_crime_stronghand_wave4[m.data2$t_ind == 0])
mean_diff <- mean_treated - mean_control
mean_diff
test_match3 = data.frame(m.data$outcome_crime_stronghand_wave4[m.data$t_ind==1],m.data$outcome_crime_stronghand_wave4[m.data$t_ind==0])
colnames(test_match3) = c("treated","control")
# Gamma = 1
senmw(test_match3,gamma=1,method="t")$pval
# Gamma = 1.1
senmw(test_match3,gamma=1.1,method="t")$pval
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
library(newrllama)
init_llama(
model_path   = "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/gemma-2-2b-it-Q5_K_M.gguf",
n_gpu_layers = 50,     # â†“ if VRAM is tight
n_ctx        = 2048,   # tokens per sequence
n_threads    = 8       # CPU threads
)
txt <- llama_infer(
prompt         = "Introduce West Lafayette.",
max_tokens     = 50,
top_k          = 20,
top_p          = 0.9,
temperature    = 0,        # 0 = deterministic / greedy
repeat_last_n  = 128,
penalty_repeat = 1.15,
seed           = 12345
)
cat(txt)
cat(llama_chat("Where is Purdue University?",max_tokens = 10), "\n")
cat(llama_chat("Who is the current president of the university?",max_tokens = 10), "\n")
llama_chat_reset()   # wipe history when youâ€™re done
qs <- c("Explain entropy.",
"888 + 890 = ?",
"What is ggplot2?")
ans <- llama_batch(qs,
max_tokens     = 40,
repeat_last_n  = 128,
penalty_repeat = 1.15)
print(ans)
llama_sentiment("I missed my flight. Terrible day!")
#> [1] Negative
# è®¾ç½®å‚æ•°
set.seed(123) # è®¾ç½®éšæœºæ•°ç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œä»£ç æ—¶ç”Ÿæˆçš„éšæœºæ•°ç›¸åŒï¼Œä»è€Œä½¿ç»“æœå¯é‡å¤ã€‚
alpha <- 0.05  # å®šä¹‰æ˜¾è‘—æ€§æ°´å¹³ï¼ˆ\alphaï¼‰ï¼Œé€šå¸¸è®¾ä¸º 0.05ï¼Œè¡¨ç¤ºåœ¨ 5% çš„é”™è¯¯ç‡ä¸‹æ£€éªŒæ˜¾è‘—æ€§ã€‚
effect_sizes <- c(0, 0, 0.14, 0.14, 0.14)  # æ§åˆ¶ç»„å‡å€¼ = 0ï¼Œå¤„ç†ç»„å‡å€¼ä¸ºå°æ•ˆåº”ï¼ˆd = 0.14 è½¬æ¢è‡ª f = 0.1ï¼‰d=f*æ ¹å·2; d=(x1_mean - x2_mean)/ä¸¤ç»„åˆå¹¶æ ‡å‡†å·®=MDE/ä¸¤ç»„åˆå¹¶æ ‡å‡†å·®
sample_sizes <- seq(100, 4000, 100)  # å®šä¹‰æ€»æ ·æœ¬é‡çš„èŒƒå›´ï¼Œä» 100 åˆ° 1000ï¼Œæ¯æ¬¡é€’å¢ 100ã€‚ f=æ•ˆåº”çš„æ ‡å‡†å·®/è¯¯å·®çš„æ ‡å‡†å·®
simulations <- 1000  # æ¯ç§æ ·æœ¬é‡çš„æ¨¡æ‹Ÿæ¬¡æ•°
group_count <- 5  # å®éªŒç»„æ•°ç›®
# åŠŸæ•ˆè®¡ç®—å‡½æ•°
simulate_power <- function(sample_size, effect_sizes, alpha, simulations) { # å®šä¹‰ä¸€ä¸ªå‡½æ•° simulate_power æ¥è®¡ç®—æŸä¸ªæ€»æ ·æœ¬é‡ä¸‹çš„åŠŸæ•ˆï¼ˆpowerï¼‰ã€‚
significant_results <- 0 # è®°å½•æ¨¡æ‹Ÿä¸­æ˜¾è‘—ç»“æœçš„æ¬¡æ•°ï¼Œåˆå§‹åŒ–ä¸º 0ã€‚
# è®¡ç®—æ¯ç»„æ ·æœ¬é‡
group_size <- sample_size / group_count
cat("Total Sample size:", sample_size,
"Each group size:", group_size, "\n") # cat() è¾“å‡ºæ€»æ ·æœ¬é‡å’Œæ¯ç»„æ ·æœ¬é‡ï¼Œæ–¹ä¾¿æ£€æŸ¥åˆ†é…æƒ…å†µã€‚
for (i in 1:simulations) {
# æ¨¡æ‹Ÿæ¯ç»„æ•°æ®
placebo     <- rnorm(group_size, mean = effect_sizes[1], sd = 1) # ä½¿ç”¨ rnorm() ç”Ÿæˆæ¯ç»„çš„éšæœºæ•°æ®ï¼Œå‡è®¾æœä»æ­£æ€åˆ†å¸ƒ
control     <- rnorm(group_size, mean = effect_sizes[2], sd = 1)
treatment1   <- rnorm(group_size, mean = effect_sizes[3], sd = 1) # meanï¼šæ¯ç»„çš„å‡å€¼ï¼Œå–è‡ª effect_sizesã€‚
treatment2   <- rnorm(group_size, mean = effect_sizes[4], sd = 1) # sd = 1ï¼šæ ‡å‡†å·®ä¸º 1ï¼Œè¡¨ç¤ºå“åº”å˜é‡çš„è‡ªç„¶æ³¢åŠ¨ã€‚
treatment3   <- rnorm(group_size, mean = effect_sizes[5], sd = 1)
# åˆå¹¶æ•°æ®
data <- data.frame( # åˆ›å»ºä¸€ä¸ªæ•°æ®æ¡† dataï¼ŒåŒ…å«ä¸¤åˆ—.
group = factor(rep(c("placebo", "Control", "Treatment1",
"Treatment2", "Treatment3"), each = group_size)), # groupï¼šè¡¨ç¤ºç»„åˆ«ï¼ˆâ€œControlâ€, â€œLowâ€, â€œMidâ€, â€œHighâ€ï¼‰ã€‚
trust = c(placebo, control, treatment1, treatment2, treatment3) # trustï¼šæ¨¡æ‹Ÿçš„ä¿¡ä»»å¾—åˆ†ã€‚
)
# è¿è¡Œå•å› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰
anova_result <- aov(trust ~ group, data = data) # ä½¿ç”¨ aov() æ£€éªŒå››ç»„çš„å‡å€¼æ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚
p_value <- summary(anova_result)[[1]][["Pr(>F)"]][1] # æå–æ–¹å·®åˆ†æç»“æœä¸­çš„ p-å€¼ï¼Œåˆ¤æ–­æ˜¯å¦æ‹’ç»é›¶å‡è®¾ã€‚
# ç»Ÿè®¡æ˜¾è‘—æ€§ç»“æœ
if (p_value < alpha) { # å¦‚æœ p-å€¼å°äºæ˜¾è‘—æ€§æ°´å¹³  \alpha = 0.05 ï¼Œè¯´æ˜ç»„é—´å·®å¼‚æ˜¾è‘—ã€‚
significant_results <- significant_results + 1 # è®°å½•æ¯æ¬¡æ¨¡æ‹Ÿä¸­æ£€æµ‹åˆ°æ˜¾è‘—ç»“æœçš„æ¬¡æ•°ã€‚
}
}
# è¿”å›åŠŸæ•ˆ
return(significant_results / simulations) # è¿”å›åŠŸæ•ˆå€¼ï¼Œå³æ˜¾è‘—ç»“æœå æ€»æ¨¡æ‹Ÿæ¬¡æ•°çš„æ¯”ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ 1000 æ¬¡æ¨¡æ‹Ÿä¸­æœ‰ 800 æ¬¡æ£€æµ‹åˆ°æ˜¾è‘—å·®å¼‚ï¼Œåˆ™åŠŸæ•ˆä¸º 0.8ï¼ˆ80%ï¼‰ã€‚
}
# è®¡ç®—ä¸åŒæ ·æœ¬é‡ä¸‹çš„åŠŸæ•ˆ
power_results <- sapply(sample_sizes, simulate_power, effect_sizes, alpha, simulations) # ä½¿ç”¨ sapply() å¯¹æ¯ä¸ªæ ·æœ¬é‡è¿è¡Œ simulate_power å‡½æ•°ã€‚ç”Ÿæˆæ¯ä¸ªæ ·æœ¬é‡å¯¹åº”çš„åŠŸæ•ˆã€‚
# å¯è§†åŒ–åŠŸæ•ˆ
plot(sample_sizes, power_results, type = "b", ylim = c(0, 1),
xlab = "Sample Size", ylab = "Power",
main = "Power to Detect Effect on Trust by Sample Size with 0.1 Standardized Effect")
abline(h = 0.8, col = "red", lty = 2)  # æ ‡è®° 80% åŠŸæ•ˆçº¿
# 6. åŠ è½½åŒ…
library(newrllama)
# åœ¨ä½ çš„ R è„šæœ¬ä¸­
# library(yourLlamaPackageName) # ç¡®ä¿ä½ çš„åŒ…å·²åŠ è½½
cat("R_SCRIPT: Calling llama_backend_init_wrapper()...\n")
llama_backend_init_wrapper()
cat("R_SCRIPT: llama_backend_init_wrapper() finished.\n")
cat("R_SCRIPT: Calling llama_load_model()...\n")
# ä½ çš„æ¨¡å‹åŠ è½½ä»£ç ï¼Œä¾‹å¦‚:
model_path <- "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/Llama-3.2-1B-Instruct.Q8_0.gguf"
model_ptr <- tryCatch({
llama_load_model(model_path, n_gpu_layers = 20, use_mmap = TRUE, use_mlock = FALSE)
}, error = function(e) {
cat("R_SCRIPT: Error during llama_load_model():\n")
print(e)
NULL
})
if (is.null(model_ptr)) {
cat("R_SCRIPT: model_ptr is NULL after llama_load_model().\n")
# è¿™é‡Œä¼šè§¦å‘ä½ ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
stop("æ‰€æœ‰å°è¯•å‡æœªèƒ½æˆåŠŸåŠ è½½æ¨¡å‹ã€‚è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€æ˜¾å­˜å’Œé”™è¯¯ä¿¡æ¯ã€‚")
} else {
cat("R_SCRIPT: model_ptr seems to be loaded.\n")
print(model_ptr)
}
ctx_ptr_single <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 1)
# ç¡®è®¤å®é™…å¯¼å‡ºçš„å‡½æ•°å
cat("newrllama è½½å…¥å®Œæˆï¼Œå½“å‰å¯ç”¨å‡½æ•°: \n")
print(ls("package:newrllama")) # ç¡®è®¤ llama_load_model å’Œ llama_backend_init_wrapper å­˜åœ¨
# 4. åˆ›å»ºå•åºåˆ—ä¸Šä¸‹æ–‡
print(paste("Current R working directory (getwd()):", getwd()))
# è¿™ä¸ªæ˜¯ ggml-metal.m å›é€€æ—¶å°è¯•çš„ç›®å½•è·¯å¾„ (æ ¹æ®ä½ çš„æ—¥å¿—)
expected_shader_dir <- "/Users/yaoshengleo/Desktop/newrllama_2/"
print(paste("Directory ggml-metal is checking for shaders (CWD fallback):", expected_shader_dir))
# æ£€æŸ¥ ggml-metal.metal å’Œ ggml-common.h æ˜¯å¦çœŸçš„åœ¨è¿™ä¸ªç›®å½•ä¸­
metal_file_path <- file.path(expected_shader_dir, "ggml-metal.metal")
common_header_path <- file.path(expected_shader_dir, "ggml-common.h")
print(paste("Does 'ggml-metal.metal' exist at expected_shader_dir?", file.exists(metal_file_path)))
print(paste("Does 'ggml-common.h' exist at expected_shader_dir?", file.exists(common_header_path)))
print(paste("Listing all files in '", expected_shader_dir, "':"))
print(list.files(expected_shader_dir))
# (ç„¶åæ˜¯ä½ è°ƒç”¨ llama_create_context çš„ä»£ç )
# ctx_ptr_single <- llama_create_context(...)
# å‡è®¾ ggml-metal.metal å’Œ ggml-common.h éƒ½å·²ç¡®è®¤åœ¨ä¸‹é¢è¿™ä¸ªç›®å½•
metal_resources_path <- "/Users/yaoshengleo/Desktop/newrllama_2" # ç¡®ä¿è¿™ä¸ªè·¯å¾„æ˜¯æ­£ç¡®çš„
Sys.setenv(GGML_METAL_PATH_RESOURCES = metal_resources_path)
print(paste("GGML_METAL_PATH_RESOURCES set to:", Sys.getenv("GGML_METAL_PATH_RESOURCES")))
# (ç„¶åæ˜¯ä½ è°ƒç”¨ llama_create_context çš„ä»£ç )
# ctx_ptr_single <- llama_create_context(...)
ctx_ptr_single <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 1)
cat("å•åºåˆ—ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ\n")
## ------------------ ç¬¬äº”éƒ¨åˆ†ï¼šå¹¶è¡Œå¤šåºåˆ—ç”Ÿæˆ ------------------- ##
cat("\n=== ç¬¬äº”éƒ¨åˆ†ï¼šå¹¶è¡Œåºåˆ—ç”Ÿæˆ ===\n")
ctx_ptr_parallel <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 3)
prompts_raw <- c(
"Please introduce Purdue University in West Lafayette, Indiana.",
"What is the answer of five plus three?",
"What is sentiment of the following text: 'I love programming in R!'?"
)
formatted_prompts <- vapply(prompts_raw, function(p) {
llama_apply_chat_template_wrapper(model_ptr, "llama3", list(
list(role = "system", content = "You are a helpful assistant."),
list(role = "user",   content = p)
), TRUE)
}, character(1))
parallel_out <- llama_generate_parallel(
ctx_ptr_parallel, formatted_prompts,
max_tokens     = 20,
top_k          = 30,
top_p          = 0.9,
temperature    = 0.6,
repeat_last_n  = 64,
penalty_repeat = 1.15,
seed           = 54321
)
cat("å¹¶è¡Œç”Ÿæˆå®Œæˆï¼š\n--------------------------\n")
for (i in seq_along(prompts_raw)) {
cat("æç¤º ", i, "ï¼š", prompts_raw[i], "\n", sep = "")
cat("å›ç­” ", i, "ï¼š", parallel_out[[i]], "\n--------------------------\n", sep = "")
}
llama_free_context_wrapper(ctx_ptr_single)
llama_free_context_wrapper(ctx_ptr_parallel)
llama_free_model_wrapper(model_ptr)
llama_backend_free_wrapper()
## ------------------ ç¬¬å…«éƒ¨åˆ†ï¼šèµ„æºé‡Šæ”¾ & ç»“æŸ ------------------ ##
cat("\n=== ç¬¬å…«éƒ¨åˆ†ï¼šèµ„æºé‡Šæ”¾å’Œæ¸…ç† ===\n")
llama_free_context_wrapper(ctx_ptr_single)
llama_free_context_wrapper(ctx_ptr_parallel)
llama_free_model_wrapper(model_ptr)
llama_backend_free_wrapper()
cat("èµ„æºå·²å…¨éƒ¨é‡Šæ”¾ï¼Œæµ‹è¯•æµç¨‹å®Œæˆï¼\n")
llama_free_context_wrapper(ctx_ptr_parallel)
# 6. åŠ è½½åŒ…
library(newrllama)
# åœ¨ä½ çš„ R è„šæœ¬ä¸­
# library(yourLlamaPackageName) # ç¡®ä¿ä½ çš„åŒ…å·²åŠ è½½
cat("R_SCRIPT: Calling llama_backend_init_wrapper()...\n")
llama_backend_init_wrapper()
cat("R_SCRIPT: llama_backend_init_wrapper() finished.\n")
cat("R_SCRIPT: Calling llama_load_model()...\n")
# ä½ çš„æ¨¡å‹åŠ è½½ä»£ç ï¼Œä¾‹å¦‚:
model_path <- "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/Llama-3.2-1B-Instruct.Q8_0.gguf"
model_ptr <- tryCatch({
llama_load_model(model_path, n_gpu_layers = 20, use_mmap = TRUE, use_mlock = FALSE)
}, error = function(e) {
cat("R_SCRIPT: Error during llama_load_model():\n")
print(e)
NULL
})
if (is.null(model_ptr)) {
cat("R_SCRIPT: model_ptr is NULL after llama_load_model().\n")
# è¿™é‡Œä¼šè§¦å‘ä½ ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
stop("æ‰€æœ‰å°è¯•å‡æœªèƒ½æˆåŠŸåŠ è½½æ¨¡å‹ã€‚è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€æ˜¾å­˜å’Œé”™è¯¯ä¿¡æ¯ã€‚")
} else {
cat("R_SCRIPT: model_ptr seems to be loaded.\n")
print(model_ptr)
}
ctx_ptr_single <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 1)
# ç¡®è®¤å®é™…å¯¼å‡ºçš„å‡½æ•°å
cat("newrllama è½½å…¥å®Œæˆï¼Œå½“å‰å¯ç”¨å‡½æ•°: \n")
print(ls("package:newrllama")) # ç¡®è®¤ llama_load_model å’Œ llama_backend_init_wrapper å­˜åœ¨
# 4. åˆ›å»ºå•åºåˆ—ä¸Šä¸‹æ–‡
print(paste("Current R working directory (getwd()):", getwd()))
# è¿™ä¸ªæ˜¯ ggml-metal.m å›é€€æ—¶å°è¯•çš„ç›®å½•è·¯å¾„ (æ ¹æ®ä½ çš„æ—¥å¿—)
expected_shader_dir <- "/Users/yaoshengleo/Desktop/newrllama_2/"
print(paste("Directory ggml-metal is checking for shaders (CWD fallback):", expected_shader_dir))
# æ£€æŸ¥ ggml-metal.metal å’Œ ggml-common.h æ˜¯å¦çœŸçš„åœ¨è¿™ä¸ªç›®å½•ä¸­
metal_file_path <- file.path(expected_shader_dir, "ggml-metal.metal")
common_header_path <- file.path(expected_shader_dir, "ggml-common.h")
print(paste("Does 'ggml-metal.metal' exist at expected_shader_dir?", file.exists(metal_file_path)))
print(paste("Does 'ggml-common.h' exist at expected_shader_dir?", file.exists(common_header_path)))
print(paste("Listing all files in '", expected_shader_dir, "':"))
print(list.files(expected_shader_dir))
# (ç„¶åæ˜¯ä½ è°ƒç”¨ llama_create_context çš„ä»£ç )
# ctx_ptr_single <- llama_create_context(...)
# å‡è®¾ ggml-metal.metal å’Œ ggml-common.h éƒ½å·²ç¡®è®¤åœ¨ä¸‹é¢è¿™ä¸ªç›®å½•
metal_resources_path <- "/Users/yaoshengleo/Desktop/newrllama_2" # ç¡®ä¿è¿™ä¸ªè·¯å¾„æ˜¯æ­£ç¡®çš„
Sys.setenv(GGML_METAL_PATH_RESOURCES = metal_resources_path)
print(paste("GGML_METAL_PATH_RESOURCES set to:", Sys.getenv("GGML_METAL_PATH_RESOURCES")))
# (ç„¶åæ˜¯ä½ è°ƒç”¨ llama_create_context çš„ä»£ç )
# ctx_ptr_single <- llama_create_context(...)
ctx_ptr_single <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 1)
cat("å•åºåˆ—ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ\n")
## ---------------- ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡æ¿ / åˆ†è¯ / å»åˆ†è¯ --------------- ##
cat("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡æ¿åº”ç”¨å’Œåˆ†è¯åŠŸèƒ½ ===\n")
chat_messages <- list(
list(role = "system", content = "You are a helpful assistant."),
list(role = "user",   content = "Please introduce the city of West Lafayette, Indiana.")
)
# 1. åº”ç”¨ llama3 æ¨¡æ¿
formatted_prompt <- llama_apply_chat_template_wrapper(model_ptr, "llama3", chat_messages, add_ass = TRUE)
cat("æ ¼å¼åŒ–æç¤º (é¦– 200 å­—ç¬¦)ï¼š\n", substr(formatted_prompt, 1, 200), "â€¦\n\n")
# 2. åˆ†è¯ & å»åˆ†è¯æ ¡éªŒ
tokens <- llama_tokenize(model_ptr, formatted_prompt, add_bos = TRUE)
cat("Token æ•°ï¼š", length(tokens), "ï¼Œå‰ 10 ä¸ªï¼š", paste(head(tokens, 10), collapse = ", "), "\n")
detok <- llama_detokenize(model_ptr, tokens)
cat("å»åˆ†è¯æ ¡éªŒ (é¦– 120 å­—ç¬¦)ï¼š\n", substr(detok, 1, 120), "â€¦\n\n")
## ------------------ ç¬¬å››éƒ¨åˆ†ï¼šå•åºåˆ—æ–‡æœ¬ç”Ÿæˆ -------------------- ##
cat("\n=== ç¬¬å››éƒ¨åˆ†ï¼šå•åºåˆ—æ–‡æœ¬ç”Ÿæˆ ===\n")
gen_text <- llama_generate(
ctx_ptr_single, tokens,
max_tokens     = 50,
top_k          = 20,
top_p          = 0.9,
temperature    = 0.7,
repeat_last_n  = 64,
penalty_repeat = 1.1,
seed           = 12345
)
cat("ç”Ÿæˆç»“æœ:\n================\n", gen_text, "\n================\n\n", sep = "")
## ---------------- ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡æ¿ / åˆ†è¯ / å»åˆ†è¯ --------------- ##
cat("\n=== ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡æ¿åº”ç”¨å’Œåˆ†è¯åŠŸèƒ½ ===\n")
chat_messages <- list(
list(role = "system", content = "You are a helpful assistant."),
list(role = "user",   content = "what is the answer of 5 plus 3?")
)
# 1. åº”ç”¨ llama3 æ¨¡æ¿
formatted_prompt <- llama_apply_chat_template_wrapper(model_ptr, "llama3", chat_messages, add_ass = TRUE)
cat("æ ¼å¼åŒ–æç¤º (é¦– 200 å­—ç¬¦)ï¼š\n", substr(formatted_prompt, 1, 200), "â€¦\n\n")
# 2. åˆ†è¯ & å»åˆ†è¯æ ¡éªŒ
tokens <- llama_tokenize(model_ptr, formatted_prompt, add_bos = TRUE)
cat("Token æ•°ï¼š", length(tokens), "ï¼Œå‰ 10 ä¸ªï¼š", paste(head(tokens, 10), collapse = ", "), "\n")
detok <- llama_detokenize(model_ptr, tokens)
cat("å»åˆ†è¯æ ¡éªŒ (é¦– 120 å­—ç¬¦)ï¼š\n", substr(detok, 1, 120), "â€¦\n\n")
## ------------------ ç¬¬å››éƒ¨åˆ†ï¼šå•åºåˆ—æ–‡æœ¬ç”Ÿæˆ -------------------- ##
cat("\n=== ç¬¬å››éƒ¨åˆ†ï¼šå•åºåˆ—æ–‡æœ¬ç”Ÿæˆ ===\n")
gen_text <- llama_generate(
ctx_ptr_single, tokens,
max_tokens     = 100,
top_k          = 20,
top_p          = 0.9,
temperature    = 0.7,
repeat_last_n  = 64,
penalty_repeat = 1.1,
seed           = 12345
)
cat("ç”Ÿæˆç»“æœ:\n================\n", gen_text, "\n================\n\n", sep = "")
cat("ç¬¬äºŒè½®å›ç­”ï¼š\n================\n", ans_r2, "\n================\n\n", sep = "")
cat("\n=== ç¬¬å…«éƒ¨åˆ†ï¼šèµ„æºé‡Šæ”¾å’Œæ¸…ç† ===\n")
llama_free_context_wrapper(ctx_ptr_single)
llama_free_context_wrapper(ctx_ptr_parallel)
llama_free_context_wrapper(ctx_ptr_single)
## ------------------ ç¬¬äº”éƒ¨åˆ†ï¼šå¹¶è¡Œå¤šåºåˆ—ç”Ÿæˆ ------------------- ##
cat("\n=== ç¬¬äº”éƒ¨åˆ†ï¼šå¹¶è¡Œåºåˆ—ç”Ÿæˆ ===\n")
ctx_ptr_parallel <- llama_create_context(model_ptr, n_ctx = 2048, n_threads = 8, n_seq_max = 3)
prompts_raw <- c(
"Please introduce Purdue University in West Lafayette, Indiana.",
"What is the answer of five plus three?",
"What is sentiment of the following text: 'I love programming in R!'?"
)
formatted_prompts <- vapply(prompts_raw, function(p) {
llama_apply_chat_template_wrapper(model_ptr, "llama3", list(
list(role = "system", content = "You are a helpful assistant."),
list(role = "user",   content = p)
), TRUE)
}, character(1))
parallel_out <- llama_generate_parallel(
ctx_ptr_parallel, formatted_prompts,
max_tokens     = 20,
top_k          = 30,
top_p          = 0.9,
temperature    = 0.6,
repeat_last_n  = 64,
penalty_repeat = 1.15,
seed           = 54321
)
cat("å¹¶è¡Œç”Ÿæˆå®Œæˆï¼š\n--------------------------\n")
for (i in seq_along(prompts_raw)) {
cat("æç¤º ", i, "ï¼š", prompts_raw[i], "\n", sep = "")
cat("å›ç­” ", i, "ï¼š", parallel_out[[i]], "\n--------------------------\n", sep = "")
}
# 1. åŠ è½½åŒ…
cat("ğŸ“¦ [1/5] åŠ è½½ newrllama4 åŒ…...\n")
library(newrllama4)
# 2. æ£€æŸ¥å¹¶å®‰è£…åç«¯åº“
cat("â¬‡ï¸  [2/5] æ£€æŸ¥é¢„ç¼–è¯‘åç«¯åº“...\n")
if (!lib_is_installed()) {
cat("    æ­£åœ¨ä¸‹è½½é¢„ç¼–è¯‘åº“...\n")
install_newrllama()
} else {
cat("    âœ… åç«¯åº“å·²å®‰è£…\n")
}
# 3. åˆå§‹åŒ–åç«¯
cat("ğŸ”§ [3/5] åˆå§‹åŒ–åç«¯...\n")
backend_init()
# 4. åŠ è½½æ¨¡å‹
cat("ğŸ“š [4/5] åŠ è½½ Llama æ¨¡å‹...\n")
model_path <- "/Users/yaoshengleo/Desktop/ggufæ¨¡å‹/Llama-3.2-1B-Instruct.Q8_0.gguf"
if (!file.exists(model_path)) {
cat("âŒ è¯·æ›´æ–°æ¨¡å‹è·¯å¾„\n")
quit(status = 1)
}
model <- model_load(model_path, n_gpu_layers = 1000L)
cat("    âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Metal GPU åŠ é€Ÿ)\n")
# åˆ›å»ºæ¨ç†ä¸Šä¸‹æ–‡
context_single <- context_create(model, n_ctx = 512L, n_threads = 2L, n_seq_max = 1L)
context_parallel <- context_create(model, n_ctx = 512L, n_threads = 2L, n_seq_max = 4L)
# å•åºåˆ—ç”Ÿæˆ
cat("â•â•â• å•åºåˆ—æ–‡æœ¬ç”Ÿæˆ â•â•â•\n")
prompt <- "Introduce Purdue University."
tokens <- tokenize(model, prompt, add_special = TRUE)
result <- generate(context_single, tokens, max_tokens = 30L, temperature = 0.7)
cat(sprintf("è¾“å…¥: %s\n", prompt))
cat(sprintf("è¾“å‡º: %s\n\n", result))
# å¹¶è¡Œåºåˆ—ç”Ÿæˆ
cat("â•â•â• å¹¶è¡Œåºåˆ—æ–‡æœ¬ç”Ÿæˆ â•â•â•\n")
prompts <- c(
"Tell me a joke.",
"The difference between R and Python.",
"What is statistical machine learning?",
"Explain the concept of overfitting."
)
results <- generate_parallel(
context_parallel,
prompts,
max_tokens = 50L,
temperature = 0.7
)
for (i in seq_along(prompts)) {
cat(sprintf("%d. %s â†’ %s\n", i, prompts[i], results[i]))
}
cat("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼æ‰€æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ\n")
# æ¸…ç†
backend_free()
# 1. å®‰è£…æˆ–åŠ è½½devtools
# install.packages("devtools")
library(devtools)
# 2. è®¾ç½®å·¥ä½œç›®å½•åˆ°æ‚¨çš„RåŒ…å†…éƒ¨
setwd("~/Desktop/newrllama_4_project/newrllama4")
# 3. è¿è¡Œæ£€æŸ¥
#    è¿™ä¸ªå‡½æ•°ä¼šè‡ªåŠ¨å¤„ç†æ„å»ºå’Œæ£€æŸ¥çš„å…¨è¿‡ç¨‹
#    args = "--as-cran" ç¡®ä¿äº†æœ€ä¸¥æ ¼çš„æ£€æŸ¥
check(args = "--as-cran")
