#!/usr/bin/env Rscript

# æ·±åº¦è¯Šæ–­ï¼šéªŒè¯llama_vocab_is_eog()å‡½æ•°æ˜¯å¦æ­£ç¡®å·¥ä½œ
library(newrllama4)

cat("=== æ·±åº¦è¯Šæ–­llama_vocab_is_eog()å‡½æ•° ===\n\n")

# ç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
if (!lib_is_installed()) {
  install_newrllama()
}

model_path <- "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf"

cat("ğŸ“¥ åŠ è½½æ¨¡å‹å’Œä¸Šä¸‹æ–‡...\n")
model <- model_load(model_path, n_gpu_layers = 100L, verbosity = 0L)
ctx <- context_create(model, n_ctx = 512L, verbosity = 0L)

cat("âœ… æ¨¡å‹å’Œä¸Šä¸‹æ–‡å‡†å¤‡å°±ç»ª\n\n")

# æµ‹è¯•å„ç§å¯ç–‘çš„token
test_texts <- c(
  "<|eot_id|>",
  " <|eot_id|>",
  " <|eot_id|> ",
  "<|end_header_id|>",
  " <|end_header_id|>",
  " <|end_header_id|> ",
  "<|start_header_id|>",
  " <|start_header_id|>",
  " <|start_header_id|> "
)

cat("ğŸ” æµ‹è¯•å„ç§EOG tokenæ–‡æœ¬çš„tokenåŒ–:\n")
cat(strrep("-", 60), "\n")

for (text in test_texts) {
  cat(sprintf("æ–‡æœ¬: '%s'\n", text))
  
  # åˆ†è¯
  token_ids <- tokenize(model, text)
  
  # è·å–tokenæ–‡æœ¬
  token_texts <- c()
  for (id in token_ids) {
    token_text <- token_to_piece(model, id)
    token_texts <- c(token_texts, token_text)
  }
  
  cat(sprintf("  Token IDs: [%s]\n", paste(token_ids, collapse = ", ")))
  cat(sprintf("  Tokenæ–‡æœ¬: [%s]\n", paste(sapply(token_texts, function(x) sprintf("'%s'", x)), collapse = ", ")))
  
  # æ£€æŸ¥æ¯ä¸ªtokenæ˜¯å¦è¢«llama.cppè¯†åˆ«ä¸ºEOG
  eog_results <- c()
  for (i in seq_along(token_ids)) {
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦é€šè¿‡C++å±‚æ£€æŸ¥ï¼Œä½†å½“å‰APIå¯èƒ½æ²¡æœ‰å¯¼å‡º
    # æˆ‘ä»¬é€šè¿‡è§‚å¯Ÿç”Ÿæˆè¡Œä¸ºæ¥æ¨æ–­
    eog_results <- c(eog_results, "æœªçŸ¥")
  }
  
  cat(sprintf("  EOGæ£€æµ‹: [%s]\n", paste(eog_results, collapse = ", ")))
  cat("\n")
}

# é‡ç‚¹æµ‹è¯•ï¼šç”ŸæˆåŒ…å«è¿™äº›tokençš„åºåˆ—
cat("ğŸ¯ é‡ç‚¹æµ‹è¯•ï¼šå¼ºåˆ¶ç”ŸæˆEOG tokenåºåˆ—\n")
cat(strrep("-", 60), "\n")

# åˆ›å»ºä¸€ä¸ªä¼šç”ŸæˆEOG tokençš„prompt
test_prompt <- "The special token is <|eot_id"
cat(sprintf("æµ‹è¯•prompt: '%s'\n", test_prompt))

tokens_in <- tokenize(model, test_prompt)
cat(sprintf("è¾“å…¥tokens: [%s]\n", paste(tokens_in, collapse = ", ")))

# ç”Ÿæˆä¸€äº›tokensï¼Œçœ‹çœ‹æ˜¯å¦ä¼šè¢«EOGæ£€æµ‹æ•è·
result <- generate_tokens(model, ctx, tokens_in, max_tokens = 10L)
cat(sprintf("ç”Ÿæˆç»“æœ: '%s'\n", result))

# å¦‚æœç»“æœåŒ…å«å®Œæ•´çš„ <|eot_id|>ï¼Œè¯´æ˜EOGæ£€æµ‹æ²¡æœ‰å·¥ä½œ
if (grepl("<\\|eot_id\\|>", result)) {
  cat("âŒ ä¸¥é‡é—®é¢˜ï¼šllama_vocab_is_eog()æ²¡æœ‰æ­£ç¡®è¯†åˆ«<|eot_id|>å®Œæ•´token\n")
} else if (grepl("eot_id", result)) {
  cat("âš ï¸ éƒ¨åˆ†é—®é¢˜ï¼šç”Ÿæˆäº†eot_idä½†è¢«æŸç§æœºåˆ¶æˆªæ–­\n")
} else {
  cat("âœ… å¯èƒ½æ­£å¸¸ï¼šæ²¡æœ‰ç”Ÿæˆeot_idç›¸å…³å†…å®¹\n")
}

cat("\nğŸ“Š è¯Šæ–­æ€»ç»“:\n")
cat("1. llama_vocab_is_eog()å¯èƒ½æ— æ³•è¯†åˆ«multi-tokençš„EOGåºåˆ—\n")
cat("2. æˆ–è€…æ¨¡å‹æœ¬èº«çš„EOG tokenå®šä¹‰ä¸æˆ‘ä»¬çš„ç†è§£ä¸ç¬¦\n")
cat("3. éœ€è¦æ£€æŸ¥æ¨¡å‹å†…éƒ¨çš„special_eog_idsé›†åˆ\n")

# æ¸…ç†
rm(model, ctx)
backend_free()

cat("\nâœ… æ·±åº¦è¯Šæ–­å®Œæˆ\n")