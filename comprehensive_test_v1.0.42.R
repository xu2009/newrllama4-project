# Comprehensive Test Script for newrllama4 v1.0.42
# Testing parallel generation function fixes
# ==========================================

library(newrllama4)

cat("ðŸ§ª newrllama4 v1.0.42 Comprehensive Test\n")
cat("========================================\n")

# Initialize backend
cat("ðŸ”§ Initializing backend...\n")
backend_init()
cat("âœ… Backend initialized\n")

# Test configuration
test_prompts <- c(
  "What is artificial intelligence and how does it work?",
  "Explain the process of machine learning in simple terms.",
  "What are the benefits and risks of AI technology?"
)

cat("\nðŸ“ Test Prompts:\n")
for (i in seq_along(test_prompts)) {
  cat("  ", i, ": ", substr(test_prompts[i], 1, 50), "...\n", sep = "")
}

# Test parameters
max_tokens_test <- 100
cat("\nðŸŽ¯ Test Parameters:\n")
cat("  - Max tokens per response:", max_tokens_test, "\n")
cat("  - Number of parallel prompts:", length(test_prompts), "\n")
cat("  - Expected: Each response ~80-120 tokens\n")
cat("  - Expected: Coherent, well-formed responses\n")

cat("\nâš ï¸  To complete the test, you need to:\n")
cat("1. Load a model using: model <- model_load('path/to/model.gguf')\n")
cat("2. Create context using: ctx <- context_create(model, n_ctx=4096, n_seq_max=10)\n")
cat("3. Test parallel generation using:\n")
cat("   results <- generate_parallel(ctx, test_prompts, max_tokens=100)\n")
cat("\n4. Then run the verification commands:\n")
cat("   # Check response lengths\n")
cat("   lengths <- sapply(results, function(x) length(strsplit(x, ' ')[[1]]))\n")
cat("   cat('Token counts (approx):', lengths, '\\n')\n")
cat("   \n")
cat("   # Print responses for quality check\n")
cat("   for (i in seq_along(results)) {\n")
cat("     cat('Response', i, ':\\n')\n")
cat("     cat(results[i], '\\n\\n')\n")
cat("   }\n")

cat("\nðŸŽ¯ Success Criteria:\n")
cat("âœ… No errors during parallel generation\n")
cat("âœ… Each response 80-120 words (was ~10-20 before fix)\n")
cat("âœ… No strange prefixes like '?' at start\n")
cat("âœ… Coherent answers that address the questions\n")
cat("âœ… Consistent quality across all parallel responses\n")

cat("\nðŸ“Š If successful, this confirms the v1.0.42 fixes:\n")
cat("  - Fixed batch processing index calculation\n")
cat("  - Fixed token position computation\n")
cat("  - Added proper KV cache management\n")
cat("  - Added chunked processing and error recovery\n")

cat("\nðŸš€ Backend ready - load your model and test!\n")