cmake_minimum_required(VERSION 3.14) # for add_link_options and implicit target directories.
project("llama.cpp" C CXX)
include(CheckIncludeFileCXX)

# --- Custom addition for newrllama4 R package (FINAL & ROBUST v3) ---
# CRITICAL FIX for Linux and C++ standard issues:
# Set these globally BEFORE any targets or subdirectories are added.
# This ensures all compiled code (including from sub-projects) uses these settings.
set(CMAKE_POSITION_INDEPENDENT_CODE ON) # Solves the -fPIC error on Linux.
set(CMAKE_CXX_STANDARD 17)              # Solves the C++11/17 syntax errors on macOS.
set(CMAKE_CXX_STANDARD_REQUIRED ON)
# --- End of critical global settings ---

# PLAN A+: Simplified build configuration for reliable cross-platform compilation
set(CMAKE_POSITION_INDEPENDENT_CODE ON)
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# Basic llama.cpp build settings (simplified from Plan B)
set(BUILD_SHARED_LIBS OFF CACHE BOOL "Build static libraries for linking" FORCE)
set(LLAMA_BUILD_COMMON ON CACHE BOOL "Build common utils" FORCE)
set(LLAMA_BUILD_TESTS OFF CACHE BOOL "Disable tests for speed" FORCE)
set(LLAMA_BUILD_TOOLS OFF CACHE BOOL "Disable tools for speed" FORCE)
set(LLAMA_BUILD_EXAMPLES OFF CACHE BOOL "Disable examples for speed" FORCE)
set(LLAMA_BUILD_SERVER OFF CACHE BOOL "Disable server for speed" FORCE)

# Platform-specific optimizations (minimal)
if(APPLE)
    set(GGML_ACCELERATE ON CACHE BOOL "Enable Accelerate framework" FORCE)
    set(GGML_METAL OFF CACHE BOOL "Disable Metal to avoid CI file system issues" FORCE)
    set(GGML_BLAS ON CACHE BOOL "Enable BLAS support" FORCE)
endif()

# Disable problematic features for clean builds
set(LLAMA_CURL OFF CACHE BOOL "Disable curl dependency" FORCE)
set(GGML_ALL_WARNINGS OFF CACHE BOOL "Disable warnings for clean build" FORCE)

# PLAN B: Use simplified configuration for reliable builds

# --- Custom library definition (rest of v3 logic) ---

# Find the cURL library, needed for some llama.cpp features.
find_package(CURL REQUIRED)

# Check for BLAS availability on macOS - use Accelerate framework properly
if(APPLE)
    # Find Accelerate framework which includes BLAS/CBLAS
    find_library(ACCELERATE_FRAMEWORK Accelerate)
    
    if(ACCELERATE_FRAMEWORK)
        message(STATUS "Found Accelerate framework - enabling BLAS support with Accelerate")
        set(BLAS_AVAILABLE TRUE)
    else()
        message(STATUS "Accelerate framework not found - disabling BLAS backend")
        set(BLAS_AVAILABLE FALSE)
    endif()
else()
    set(BLAS_AVAILABLE FALSE)
endif()

# 1. Define our own shared library target.
#    PLAN A+: Minimal targeted source inclusion for missing symbols
add_library(newrllama SHARED
    newrllama_capi.cpp
    # ESSENTIAL MISSING SYMBOLS: Add only the specific files containing missing functions
    ggml/src/gguf.cpp        # For gguf_type_name, gguf_write_to_file 
    ggml/src/ggml.c          # For ggml_view_1d/2d/3d/4d and core tensor operations
)

# Add platform-specific backend sources only if they're not in static libraries
if(APPLE)
    # Check if we need to add any platform-specific sources
    # For now, rely entirely on static library linking
    message(STATUS "Using static library linking for all GGML functionality on macOS")
endif()

# 2. Add dependencies to ensure correct build order.
add_dependencies(newrllama llama common ggml)

# 3. Link system libraries and frameworks.
target_link_libraries(newrllama PRIVATE
    CURL::libcurl      # Use CMake's official way to link curl
)

# 3.1. Link essential system libraries for all platforms
if(UNIX)
    target_link_libraries(newrllama PRIVATE m pthread)  # math and threading libraries
endif()

# 3.2. Link Apple frameworks if on macOS
if(APPLE)
    # Link required Apple frameworks
    if(ACCELERATE_FRAMEWORK)
        target_link_libraries(newrllama PRIVATE ${ACCELERATE_FRAMEWORK})
        # Set BLAS-related compile definitions
        target_compile_definitions(newrllama PRIVATE 
            GGML_USE_ACCELERATE
            GGML_BLAS_USE_ACCELERATE
            ACCELERATE_NEW_LAPACK
        )
    endif()
    
    # Metal disabled due to CI file system permission issues
    # find_library(METAL_FRAMEWORK Metal)
    # find_library(METALKIT_FRAMEWORK MetalKit)
    
    # Link Foundation framework for basic macOS/iOS types
    find_library(FOUNDATION_FRAMEWORK Foundation)
    if(FOUNDATION_FRAMEWORK)
        target_link_libraries(newrllama PRIVATE ${FOUNDATION_FRAMEWORK})
    endif()
endif()

# 4. Statically link the internal libraries using platform-specific flags.
if(APPLE)
    target_link_options(newrllama PRIVATE
        "-Wl,-force_load,$<TARGET_FILE:llama>"
        "-Wl,-force_load,$<TARGET_FILE:common>"
        "-Wl,-force_load,$<TARGET_FILE:ggml>"
    )
elseif(UNIX AND NOT APPLE)
    target_link_libraries(newrllama PRIVATE
        "-Wl,--whole-archive" llama common ggml "-Wl,--no-whole-archive"
    )
elseif(WIN32)
    target_link_options(newrllama PRIVATE 
        "/WHOLEARCHIVE:$<TARGET_FILE_NAME:llama>"
        "/WHOLEARCHIVE:$<TARGET_FILE_NAME:common>"
        "/WHOLEARCHIVE:$<TARGET_FILE_NAME:ggml>"
    )
endif()

# 5. Add necessary include directories for 'newrllama_capi.cpp'.
target_include_directories(newrllama PRIVATE
    "${CMAKE_CURRENT_SOURCE_DIR}/include"
    "${CMAKE_CURRENT_SOURCE_DIR}/common"
    "${CMAKE_CURRENT_SOURCE_DIR}/ggml/include"
    "${CMAKE_CURRENT_SOURCE_DIR}/ggml/src"        # For ggml-impl.h
    "${CMAKE_CURRENT_SOURCE_DIR}/ggml/src/ggml-cpu"  # For ggml-cpu-impl.h
)

# 6. Set final properties for our library.
set_target_properties(newrllama PROPERTIES
    OUTPUT_NAME "newrllama"
    C_VISIBILITY_PRESET default
    CXX_VISIBILITY_PRESET default
)

# PLAN A+: Clean, minimal configuration

# Include original llama.cpp build logic (we ARE the CMakeLists.txt now)
include(${CMAKE_CURRENT_SOURCE_DIR}/cmake/build-info.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/cmake/common.cmake)

# Add ggml subdirectory
add_subdirectory(ggml)

# Add llama src subdirectory  
add_subdirectory(src)

# Add common subdirectory
if (LLAMA_BUILD_COMMON)
    add_subdirectory(common)
endif()
